% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{ref20}
A.~E. Hoerl and R.~W. Kennard, ``Ridge regression: Biased estimation for
  nonorthogonal problems,'' \emph{Technometrics}, vol.~42, no.~1, pp. 80--86,
  1970.

\bibitem{ref21}
D.~W. Marquardt, ``Generalized inverses, ridge regression, biased linear
  estimation, and nonlinear estimation,'' \emph{Technometrics}, vol.~12, no.~3,
  pp. 591--612, 1970.

\bibitem{ref22}
R.~Tibshirani, ``Regression shrinkage and selection via the lasso: a
  retrospective,'' \emph{Journal of the Royal Statistical Society}, vol.~73,
  no.~3, pp. 273--282, 2011.

\bibitem{ref23}
B.~Efron, T.~Hastie, I.~Johnstone, and R.~Tibshirani, ``Least angle
  regression,'' \emph{Annals of Statistics}, vol.~32, no.~2, pp. 407--451,
  2004.

\bibitem{ref24}
Z.~Hui and T.~Hastie, ``Regularization and variable selection via the elastic
  net,'' \emph{Journal of the Royal Statistical Society}, vol.~67, no.~2, pp.
  301--320, 2005.

\bibitem{ref01}
T.~W. Anderson, ``Estimating linear restrictions on regression coefficients for
  multivariate normal distributions,'' \emph{Annals of Mathematical
  Statistics}, vol.~22, no.~3, pp. 327--351, 1951.

\bibitem{ref07}
F.~Bunea, Y.~She, and M.~H. Wegkamp, ``Optimal selection of reduced rank
  estimators of high-dimensional matrices,'' \emph{Annals of Statistics},
  vol.~39, no.~2, pp. 1282--1309, 2011.

\bibitem{ref12}
S.~Zheng, X.~Cai, C.~Ding, F.~Nie, and H.~Huang, ``A closed form solution to
  multi-view low-rank regression,'' in \emph{Twenty-Ninth AAAI Conference on
  Artificial Intelligence}, 2015, pp. 1973--1979.

\bibitem{ref14}
J.~F. Cai, Cand, E.~J. S, and Z.~Shen, ``A singular value thresholding
  algorithm for matrix completion,'' \emph{Siam Journal on Optimization},
  vol.~20, no.~4, pp. 1956--1982, 2008.

\bibitem{ref30}
G.~C. Reinsel and R.~P. Velu, \emph{Multivariate Reduced-Rank
  Regression}.\hskip 1em plus 0.5em minus 0.4em\relax Springer,, 1998.

\bibitem{ref31}
T.~Hochkirchen, ``Modern multivariate statistical techniques: Regression,
  classification, and manifold learning,'' \emph{Journal of the Royal
  Statistical Society}, vol. 173, no.~2, pp. 2536--2541, 2010.

\bibitem{ref27}
A.~J. Izenman, ``Reduced-rank regression for the multivariate linear model,''
  \emph{Journal of Multivariate Analysis}, vol.~5, no.~2, pp. 248--264, 1975.

\bibitem{ref26}
A.~Mukherjee and J.~Zhu, ``Reduced rank ridge regression and its kernel
  extensions,'' \emph{Statistical Analysis and Data Mining}, vol.~4, no.~6, p.
  612, 2011.

\bibitem{ref11}
X.~Cai, C.~Ding, F.~Nie, and H.~Huang, ``On the equivalent of low-rank linear
  regressions and linear discriminant analysis based regressions,'' in
  \emph{ACM SIGKDD International Conference on Knowledge Discovery and Data
  Mining}, 2013, pp. 1124--1132.

\bibitem{ref28}
G.~Rabusseau and H.~Kadri, ``Low-rank regression with tensor responses,'' in
  \emph{Advances in Neural Information Processing Systems 29}, D.~D. Lee,
  M.~Sugiyama, U.~V. Luxburg, I.~Guyon, and R.~Garnett, Eds.\hskip 1em plus
  0.5em minus 0.4em\relax Curran Associates, Inc., 2016, pp. 1867--1875.

\bibitem{ref29}
J.~Qian, J.~Yang, F.~Zhang, and Z.~Lin, ``Robust low-rank regularized
  regression for face recognition with occlusion,'' in \emph{IEEE Conference on
  Computer Vision and Pattern Recognition Workshops}, 2014, pp. 21--26.

\bibitem{ref02}
M.~Yuan, ``Dimension reduction and coefficient estimation in multivariate
  linear regression,'' \emph{Journal of the Royal Statistical Society},
  vol.~69, no.~3, pp. 329--346, 2007.

\bibitem{ref03}
Toh, Kim-Chuan, Yun, and Sangwoon, ``An accelerated proximal gradient algorithm
  for nuclear norm regularized least squares problems,'' \emph{Pacific Journal
  of Optimization}, vol.~6, no.~3, pp. 615--640, 2009.

\bibitem{ref04}
D.~Ruppert, ``The elements of statistical learning: Data mining, inference, and
  prediction,'' \emph{Mathematical Intelligencer}, vol.~99, no. 466, pp.
  567--567, 2010.

\bibitem{ref33}
D.~Huang, R.~S. Cabral, and F.~D.~L. Torre, ``Robust regression,'' \emph{IEEE
  Transactions on Pattern Analysis and Machine Intelligence}, vol.~38, no.~2,
  pp. 363--375, 2016.

\bibitem{ref32}
Y.~Zhang, D.~Shi, J.~Gao, and D.~Cheng, ``Low-rank-sparse subspace
  representation for robust regression,'' in \emph{IEEE Conference on Computer
  Vision and Pattern Recognition}, 2017, pp. 7445--7454.

\bibitem{ref34}
Q.~Li, Y.~Liu, S.~Wang, Q.~Gao, and X.~Gao, ``Image classification using
  low-rank regularized extreme learning machine,'' \emph{IEEE Access}, vol.~7,
  pp. 877--883, 2018.

\bibitem{ref19}
A.~Hoerl and R.~Kennard, ``Ridge regression: Biased estimation for
  nonorthogonal problems,'' \emph{Technometrics}, vol.~12, no.~1, pp. 55--67,
  2000.

\bibitem{ref25}
A.~Mukherjee and J.~Zhu, ``Reduced rank ridge regression and its kernel
  extensions.'' \emph{Statistical Analysis and Data Mining}, vol.~4, no.~6, pp.
  612--622, 2011.

\bibitem{ref18}
H.~Lian and S.~Ma, ``Reduced-rank regression in sparse multivariate
  varying-coefficient models with high-dimensional covariates,''
  \emph{Statistics}, 2013.

\bibitem{ref13}
D.~P. Bertsekas, \emph{Constrained optimization and Lagrange multiplier
  methods}.\hskip 1em plus 0.5em minus 0.4em\relax Academic Press, 1982.

\bibitem{ref36}
N.~Liqiang, S.~Xuemeng, and C.~Tatseng, ``Learning from multiple social
  networks,'' \emph{Synthesis Lectures on Information Concepts, Retrieval, and
  Services, Morgan Claypool Publishers}, 2016.

\bibitem{ref37}
S.~R¨¹ping and T.~Scheffer, ``Learning with multiple views,'' \emph{In Proc.
  ICML Workshop on Learning with Multiple Views}, 2005.

\bibitem{ref38}
B.~C. J. C.~. Zhou~D, ``Spectral clustering and transductive learning with
  multiple views,'' \emph{Machine Learning, Twenty-fourth International
  Conference, Corvallis, Oregon, Usa, June.}, 2007.

\bibitem{ref15}
A.~M. Martinez, ``The ar face database,'' \emph{Cvc Technical Report}, vol.~24,
  1998.

\bibitem{ref16}
J.~L. Yong and K.~Grauman, ``Foreground focus: Unsupervised learning from
  partially matching images,'' \emph{International Journal of Computer Vision},
  vol.~85, no.~2, pp. 143--166, 2009.

\end{thebibliography}
